{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G6gvCgiQwuNe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2.2\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Import Libraries ========== ----- ========== #\n",
        "\n",
        "from joblib import dump, load\n",
        "from collections import Counter\n",
        "import pickle\n",
        "from LDP import LDP_TOP\n",
        "from LDP import train\n",
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Reading Training Data ========== ----- ========== #\n",
        "\n",
        "# Reading Training Data\n",
        "train_frame_folders = [\n",
        "    'datasets/cf40/faceforensics_dataset_train/original_sequences',\n",
        "    'datasets/cf40/faceforensics_dataset_train/manipulated_sequences/Deepfakes',\n",
        "    # 'datasets/cf40/faceforensics_dataset_train/manipulated_sequences/Face2Face',\n",
        "    # 'datasets/cf40/faceforensics_dataset_train/manipulated_sequences/FaceSwap',\n",
        "    # 'datasets/cf40/faceforensics_dataset_train/manipulated_sequences/NeuralTextures'\n",
        "]\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets/cf40/faceforensics_dataset_train/original_sequences videos:  860\n",
            "datasets/cf40/faceforensics_dataset_train/manipulated_sequences/Deepfakes videos:  860\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Feature Extraction ========== ----- ========== #\n",
        "\n",
        "# Face detector\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "list_of_train_LDP = []\n",
        "list_of_train_labels = []\n",
        "\n",
        "for train_frame_folder in train_frame_folders:\n",
        "    list_of_train_data = [f for f in os.listdir(\n",
        "        train_frame_folder) if f.endswith('.mp4')]\n",
        "    print(train_frame_folder, 'videos: ', len(list_of_train_data))\n",
        "    for vid in list_of_train_data:\n",
        "        frames = []\n",
        "        # Video capturing constructor.\n",
        "        cap = cv2.VideoCapture(os.path.join(train_frame_folder, vid))\n",
        "\n",
        "        # (CAP_PROP_FPS) Returns frame rate of the video (#frames / second).\n",
        "        frameRate = cap.get(5)\n",
        "        while cap.isOpened():  # Returns true if video capturing has been initialized already.\n",
        "\n",
        "            # (CAP_PROP_POS_MSEC) Current position of the video file in milliseconds or video capture timestamp.\n",
        "            frameId = cap.get(1)\n",
        "            ret, frame = cap.read()  # The methods/functions combine VideoCapture::grab and VideoCapture::retrieve in one call. This is the most convenient method for reading video files or capturing data from decode and return the just grabbed frame. If no frames has been grabbed (camera has been disconnected, or there are no more frames in video file), the methods return false and the functions return NULL pointer.\n",
        "            if ret != True:\n",
        "                break\n",
        "\n",
        "            face_rects, scores, idx = detector.run(frame, 0)\n",
        "            for i, d in enumerate(face_rects):\n",
        "                x1 = d.left()\n",
        "                y1 = d.top()\n",
        "                x2 = d.right()\n",
        "                y2 = d.bottom()\n",
        "\n",
        "                crop_img = frame[y1:y2, x1:x2]\n",
        "                if crop_img is not None and crop_img.size > 0:\n",
        "                    crop_img = cv2.resize(crop_img, (128, 128))\n",
        "                    gray_scale_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
        "                    frames.append(gray_scale_img)\n",
        "\n",
        "            # d = 3 seconds.\n",
        "            if frameId % ((int(frameRate)+1)*3) == 0:\n",
        "                if (len(frames) > 0):\n",
        "                    frames_ldp = LDP_TOP(np.array(frames).astype(np.float64))\n",
        "                    list_of_train_LDP.append(frames_ldp)\n",
        "                    if train_frame_folder == 'datasets/cf40/faceforensics_dataset_train/original_sequences':\n",
        "                        list_of_train_labels.append(0)\n",
        "                    else:\n",
        "                        list_of_train_labels.append(1)\n",
        "                frames = []\n",
        "\n",
        "with open('list_of_train_LDP_original_Deepfakes.pkl', 'wb') as f:\n",
        "    pickle.dump(list_of_train_LDP, f)\n",
        "\n",
        "with open('list_of_train_labels_original_Deepfakes.pkl', 'wb') as f:\n",
        "    pickle.dump(list_of_train_labels, f)\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'features/cf40/list_of_train_LDP_original_Deepfakes.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# ========== ----- ========== Load Features ========== ----- ========== #\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# Loading the list_of_train_LDP\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mfeatures/cf40/list_of_train_LDP_original_Deepfakes.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     list_of_train_LDP \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Loading the list_of_train_labels\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features/cf40/list_of_train_LDP_original_Deepfakes.pkl'"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Load Features ========== ----- ========== #\n",
        "\n",
        "# Loading the list_of_train_LDP\n",
        "with open('features/cf40/list_of_train_LDP_original_Deepfakes.pkl', 'rb') as f:\n",
        "    list_of_train_LDP = pickle.load(f)\n",
        "\n",
        "# Loading the list_of_train_labels\n",
        "with open('features/cf40/list_of_train_labels_original_Deepfakes.pkl', 'rb') as f:\n",
        "    list_of_train_labels = pickle.load(f)\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 5666\n",
            "1: 5666\n",
            "2: 5669\n",
            "3: 4570\n",
            "4: 4570\n",
            "0: 5666\n",
            "4: 4570\n",
            "0: 5666\n",
            "1: 4570\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Prepare Features ========== ----- ========== #\n",
        "\n",
        "counts = Counter(list_of_train_labels)\n",
        "\n",
        "for value, count in counts.items():\n",
        "    print(f\"{value}: {count}\")\n",
        "\n",
        "# NeuralTextures\n",
        "list_of_train_labels = list_of_train_labels[:5666] + \\\n",
        "    list_of_train_labels[21571:26141]\n",
        "\n",
        "list_of_train_LDP = list_of_train_LDP[:5666] + \\\n",
        "    list_of_train_LDP[21571:26141]\n",
        "\n",
        "counts = Counter(list_of_train_labels)\n",
        "\n",
        "for value, count in counts.items():\n",
        "    print(f\"{value}: {count}\")\n",
        "\n",
        "list_of_train_labels = [0] * 5666 + [1] * 4570\n",
        "\n",
        "counts = Counter(list_of_train_labels)\n",
        "\n",
        "for value, count in counts.items():\n",
        "    print(f\"{value}: {count}\")\n",
        "    \n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Linear-Deepfakes.joblib']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ========== ----- ========== Training SVM ========== ----- ========== #\n",
        "\n",
        "# model = svm.SVC(kernel='rbf')\n",
        "# model.fit(list_of_train_LDP, list_of_train_labels)\n",
        "# # Save the trained model to a file\n",
        "# dump(model, 'RBF-Deepfakes.joblib')\n",
        "\n",
        "# ================================================ #\n",
        "\n",
        "model = svm.SVC(kernel='linear')\n",
        "model.fit(list_of_train_LDP, list_of_train_labels)\n",
        "# Save the trained model to a file\n",
        "dump(model, 'Linear-Deepfakes.joblib')\n",
        "\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DS_LDPcode.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
