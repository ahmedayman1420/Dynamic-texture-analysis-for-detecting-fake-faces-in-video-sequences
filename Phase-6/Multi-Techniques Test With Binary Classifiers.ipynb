{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2.2\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Import Libraries ========== ----- ========== #\n",
        "\n",
        "from joblib import dump, load\n",
        "from collections import Counter\n",
        "from LDP import LDP_TOP\n",
        "from LDP import train\n",
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pickle\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Load SVM Model ========== ----- ========== #\n",
        "\n",
        "# Load the saved model from the file\n",
        "linear_Deepfakes = load('models/Linear-Deepfakes.joblib')\n",
        "linear_Face2Face = load('models/Linear-Face2Face.joblib')\n",
        "linear_FaceSwap = load('models/Linear-FaceSwap.joblib')\n",
        "linear_NeuralTextures = load('models/Linear-NeuralTextures.joblib')\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Reading Test Data ========== ----- ========== #\n",
        "\n",
        "# Reading Testing Data\n",
        "test_frame_folders = [\n",
        "    # 'faceforensics_dataset_test/original_sequences',\n",
        "    # 'faceforensics_dataset_test/manipulated_sequences/Deepfakes',\n",
        "    'faceforensics_dataset_test/manipulated_sequences/Face2Face',\n",
        "    'faceforensics_dataset_test/manipulated_sequences/FaceSwap',\n",
        "    'faceforensics_dataset_test/manipulated_sequences/NeuralTextures'\n",
        "]\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "faceforensics_dataset_test/manipulated_sequences/Face2Face videos:  140\n",
            "faceforensics_dataset_test/manipulated_sequences/FaceSwap videos:  140\n",
            "faceforensics_dataset_test/manipulated_sequences/NeuralTextures videos:  140\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Feature Extraction ========== ----- ========== #\n",
        "\n",
        "# Face detector\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "list_of_test_LDP = []\n",
        "list_of_test_labels = []\n",
        "\n",
        "index = 0\n",
        "for test_frame_folder in test_frame_folders:\n",
        "    list_of_test_data = [f for f in os.listdir(\n",
        "        test_frame_folder) if f.endswith('.mp4')]\n",
        "    \n",
        "    print(test_frame_folder, 'videos: ', len(list_of_test_data))\n",
        "    for vid in list_of_test_data:\n",
        "        list_of_test_LDP.append([])\n",
        "        frames = []\n",
        "        # Video capturing constructor.\n",
        "        cap = cv2.VideoCapture(os.path.join(test_frame_folder, vid))\n",
        "\n",
        "        # (CAP_PROP_FPS) Returns frame rate of the video (#frames / second).\n",
        "        frameRate = cap.get(5)\n",
        "        while cap.isOpened():  # Returns true if video capturing has been initialized already.\n",
        "            # (CAP_PROP_POS_MSEC) Current position of the video file in milliseconds or video capture timestamp.\n",
        "            frameId = cap.get(1)\n",
        "            ret, frame = cap.read()  # The methods/functions combine VideoCapture::grab and VideoCapture::retrieve in one call. This is the most convenient method for reading video files or capturing data from decode and return the just grabbed frame. If no frames has been grabbed (camera has been disconnected, or there are no more frames in video file), the methods return false and the functions return NULL pointer.\n",
        "            if ret != True:\n",
        "                break\n",
        "\n",
        "            face_rects, scores, idx = detector.run(frame, 0)\n",
        "            for i, d in enumerate(face_rects):\n",
        "                x1 = d.left()\n",
        "                y1 = d.top()\n",
        "                x2 = d.right()\n",
        "                y2 = d.bottom()\n",
        "\n",
        "                crop_img = frame[y1:y2, x1:x2]\n",
        "                if crop_img is not None and crop_img.size > 0:\n",
        "                    crop_img = cv2.resize(crop_img, (128, 128))\n",
        "                    gray_scale_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
        "                    frames.append(gray_scale_img)\n",
        "\n",
        "            # d = 3 seconds.\n",
        "            if frameId % ((int(frameRate)+1)*3) == 0:\n",
        "                if (len(frames) > 0):\n",
        "                    frames_ldp = LDP_TOP(np.array(frames).astype(np.float64))\n",
        "                    list_of_test_LDP[index].append(frames_ldp)\n",
        "\n",
        "                frames = []\n",
        "        index += 1\n",
        "\n",
        "with open('features/Face2Face-FaceSwap-NeuralTextures-Test.pkl', 'wb') as f:\n",
        "    pickle.dump(list_of_test_LDP, f)\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Feature Loading ========== ----- ========== #\n",
        "\n",
        "# Loading the list_of_train_LDP\n",
        "with open('features/Original-Deepfakes-Test.pkl', 'rb') as f:\n",
        "    test_features_p1 = pickle.load(f)\n",
        "\n",
        "# Loading the list_of_train_labels\n",
        "with open('features/Face2Face-FaceSwap-NeuralTextures-Test.pkl', 'rb') as f:\n",
        "    test_features_p2 = pickle.load(f)\n",
        "\n",
        "test_features = test_features_p1 + test_features_p2\n",
        "\n",
        "list_of_test_LDP = test_features\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== SVM Predictions ========== ----- ========== #\n",
        "\n",
        "linear_predictions = []\n",
        "\n",
        "for vid in list_of_test_LDP:\n",
        "\n",
        "    y_pred = []\n",
        "    y_score = []\n",
        "\n",
        "    df_pred = linear_Deepfakes.predict(vid)\n",
        "    if np.count_nonzero(df_pred == 1) >= np.count_nonzero(df_pred == 0):\n",
        "        y_score.append(np.count_nonzero(df_pred == 1))\n",
        "        y_pred.append(1)\n",
        "    else:\n",
        "        y_score.append(np.count_nonzero(df_pred == 0))\n",
        "        y_pred.append(0)\n",
        "\n",
        "    # ============================================= #\n",
        "\n",
        "    f2f_pred = linear_Face2Face.predict(vid)\n",
        "    if np.count_nonzero(f2f_pred == 1) >= np.count_nonzero(f2f_pred == 0):\n",
        "        y_score.append(np.count_nonzero(f2f_pred == 1))\n",
        "        y_pred.append(1)\n",
        "    else:\n",
        "        y_score.append(np.count_nonzero(f2f_pred == 0))\n",
        "        y_pred.append(0)\n",
        "\n",
        "# ============================================= #\n",
        "\n",
        "    fsw_pred = linear_FaceSwap.predict(vid)\n",
        "    if np.count_nonzero(fsw_pred == 1) >= np.count_nonzero(fsw_pred == 0):\n",
        "        y_score.append(np.count_nonzero(fsw_pred == 1))\n",
        "        y_pred.append(1)\n",
        "    else:\n",
        "        y_score.append(np.count_nonzero(fsw_pred == 0))\n",
        "        y_pred.append(0)\n",
        "\n",
        "# ============================================= #\n",
        "\n",
        "    nt_pred = linear_NeuralTextures.predict(vid)\n",
        "    if np.count_nonzero(nt_pred == 1) >= np.count_nonzero(nt_pred == 0):\n",
        "        y_score.append(np.count_nonzero(nt_pred == 1))\n",
        "        y_pred.append(1)\n",
        "    else:\n",
        "        y_score.append(np.count_nonzero(nt_pred == 0))\n",
        "        y_pred.append(0)\n",
        "\n",
        "# ============================================= #\n",
        "    \n",
        "    # if y_pred.count(1) > 0:\n",
        "    #     max_score = -1\n",
        "    #     index = 0\n",
        "    #     target_index = -1\n",
        "    #     for pred, score in zip(y_pred, y_score):\n",
        "    #         if pred == 1 and max_score < score:\n",
        "    #             max_score = score\n",
        "    #             target_index = index\n",
        "    #         index+=1\n",
        "    #     linear_predictions.append(target_index+1)\n",
        "    # else:\n",
        "    #     linear_predictions.append(0)\n",
        "\n",
        "    if y_pred.count(1) > 0:\n",
        "        linear_predictions.append(1)\n",
        "    else:\n",
        "        linear_predictions.append(0)\n",
        "\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Accuracy: 0.91\n",
            "Linear Confusion matrix:\n",
            " [[102  38]\n",
            " [ 25 535]]\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== SVM Accuracy ========== ----- ========== #\n",
        "\n",
        "labels = [0]*140 + [1]*560\n",
        "\n",
        "# calculate the accuracy score and print it out\n",
        "accuracy = accuracy_score(labels, linear_predictions)\n",
        "print(\"Linear Accuracy:\", accuracy)\n",
        "\n",
        "# calculate the confusion matrix and print it out\n",
        "cm = confusion_matrix(labels, linear_predictions)\n",
        "print(\"Linear Confusion matrix:\\n\", cm)\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DS_LDPcode.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
