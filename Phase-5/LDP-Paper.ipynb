{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6gvCgiQwuNe"
      },
      "outputs": [],
      "source": [
        "# ========== ----- ========== Import Libraries ========== ----- ========== #\n",
        "\n",
        "\n",
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from joblib import dump, load\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Local Derivative Pattern Services For Image ========== ----- ========== #\n",
        "\n",
        "def F(a, b):\n",
        "    if a*b > 0:\n",
        "        return \"0\"\n",
        "    elif a*b <= 0:\n",
        "        return \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def I(picture, h, w, theta):\n",
        "    if (theta == 0):\n",
        "        return picture[h,w] - picture[h,w+1]\n",
        "    elif (theta == 45):\n",
        "        return picture[h, w] - picture[h-1, w+1]\n",
        "    elif (theta == 90):\n",
        "        return picture[h, w] - picture[h-1, w]\n",
        "    elif (theta == 135):\n",
        "        return picture[h, w] - picture[h-1, w-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ldp_pixel(picture, h, w):  # calculating local derivative pattern value of a pixel\n",
        "    eigth_bit_binary = []\n",
        "    four_decimal_val = []\n",
        "    decimal_val = 0\n",
        "    angles = [0, 45, 90, 135]\n",
        "\n",
        "    for theta in angles:\n",
        "\n",
        "        # starting from top left,assigning bit to pixels clockwise at theta degree\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h-1, w-1, theta)))\n",
        "\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h-1, w, theta)))\n",
        "\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h-1, w+1, theta)))\n",
        "\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h, w+1, theta)))\n",
        "\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h+1, w+1, theta)))\n",
        "\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h+1, w, theta)))\n",
        "\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h+1, w-1, theta)))\n",
        "\n",
        "        eigth_bit_binary.append(\n",
        "            F(I(picture, h, w, theta), I(picture, h, w-1, theta)))\n",
        "\n",
        "        l = \"\".join(eigth_bit_binary)\n",
        "        decimal_val = int(l, 2)\n",
        "        four_decimal_val.append(decimal_val)\n",
        "        eigth_bit_binary = []\n",
        "\n",
        "    return four_decimal_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ldp_img(img):\n",
        "    m, n = img.shape\n",
        "    # converting image to grayscale\n",
        "    # ldp_photo = np.zeros((m, n),np.uint8)\n",
        "    ldp_img = np.zeros((m, n, 4))\n",
        "    # converting image to ldp\n",
        "    for i in range(2, m-2):\n",
        "        for j in range(2, n-2):\n",
        "            ldp_pixels = ldp_pixel(img, i, j)\n",
        "            ldp_img[i, j, 0] = ldp_pixels[0]\n",
        "            ldp_img[i, j, 1] = ldp_pixels[1]\n",
        "            ldp_img[i, j, 2] = ldp_pixels[2]\n",
        "            ldp_img[i, j, 3] = ldp_pixels[3]\n",
        "\n",
        "    return ldp_img\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Local Derivative Pattern Main Function For Image ========== ----- ========== #\n",
        "\n",
        "def extract_hist(gray_scale_img):\n",
        "\n",
        "    features = ldp_img(gray_scale_img)\n",
        "\n",
        "    histogram_0, bin_edges = np.histogram(\n",
        "        features[:, :, 0], bins=256, range=(0, 256))\n",
        "\n",
        "    histogram_45, bin_edges = np.histogram(\n",
        "        features[:, :, 1], bins=256, range=(0, 256))\n",
        "\n",
        "    histogram_90, bin_edges = np.histogram(\n",
        "        features[:, :, 2], bins=256, range=(0, 256))\n",
        "\n",
        "    histogram_135, bin_edges = np.histogram(\n",
        "        features[:, :, 3], bins=256, range=(0, 256))\n",
        "\n",
        "    hist = np.concatenate((histogram_0, histogram_45, histogram_90, histogram_135))\n",
        "\n",
        "    return hist\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Local Derivative Pattern Main Function For TOP ========== ----- ========== #\n",
        "\n",
        "def LDP_TOP(frames):\n",
        "\n",
        "    x, y, z = frames.shape\n",
        "    plane_yz = frames[(x//2), :, :]\n",
        "    plane_xz = frames[:, (y//2), :]\n",
        "    plane_xy = frames[:, :, (z//2)]\n",
        "\n",
        "    hist_yz = extract_hist(plane_yz)\n",
        "    hist_xz = extract_hist(plane_xz)\n",
        "    hist_xy = extract_hist(plane_xy)\n",
        "    \n",
        "    hist_TOP = np.concatenate((hist_yz, hist_xz, hist_xy))\n",
        "    return hist_TOP\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Reading Training Data ========== ----- ========== #\n",
        "\n",
        "# Reading Training Data\n",
        "train_frame_folders = [\n",
        "    'faceforensics_dataset_train/original_sequences',\n",
        "    'faceforensics_dataset_train/manipulated_sequences/Deepfakes',\n",
        "    # 'faceforensics_dataset_train/manipulated_sequences/Face2Face',\n",
        "    # 'faceforensics_dataset_train/manipulated_sequences/FaceSwap',\n",
        "    # 'faceforensics_dataset_train/manipulated_sequences/NeuralTextures'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Face detector\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "list_of_train_LDP = []\n",
        "list_of_train_labels = []\n",
        "\n",
        "for train_frame_folder in train_frame_folders:\n",
        "    list_of_train_data = [f for f in os.listdir(\n",
        "        train_frame_folder) if f.endswith('.mp4')]\n",
        "\n",
        "    for vid in list_of_train_data:\n",
        "        frames = []\n",
        "        # Video capturing constructor.\n",
        "        cap = cv2.VideoCapture(os.path.join(train_frame_folder, vid))\n",
        "\n",
        "        # (CAP_PROP_FPS) Returns frame rate of the video (#frames / second).\n",
        "        frameRate = cap.get(5)\n",
        "        while cap.isOpened():  # Returns true if video capturing has been initialized already.\n",
        "\n",
        "            # (CAP_PROP_POS_MSEC) Current position of the video file in milliseconds or video capture timestamp.\n",
        "            frameId = cap.get(1)\n",
        "            ret, frame = cap.read()  # The methods/functions combine VideoCapture::grab and VideoCapture::retrieve in one call. This is the most convenient method for reading video files or capturing data from decode and return the just grabbed frame. If no frames has been grabbed (camera has been disconnected, or there are no more frames in video file), the methods return false and the functions return NULL pointer.\n",
        "            if ret != True:\n",
        "                break\n",
        "\n",
        "            face_rects, scores, idx = detector.run(frame, 0)\n",
        "            for i, d in enumerate(face_rects):\n",
        "                x1 = d.left()\n",
        "                y1 = d.top()\n",
        "                x2 = d.right()\n",
        "                y2 = d.bottom()\n",
        "\n",
        "                crop_img = frame[y1:y2, x1:x2]\n",
        "                if crop_img is not None and crop_img.size > 0:\n",
        "                    crop_img = cv2.resize(crop_img, (128, 128))\n",
        "                    gray_scale_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
        "                    frames.append(gray_scale_img)\n",
        "            \n",
        "            # d = 3 seconds.\n",
        "            if frameId % ((int(frameRate)+1)*3) == 0:\n",
        "                if (len(frames) > 0):\n",
        "                    frames_ldp = LDP_TOP(np.array(frames).astype(np.float64))\n",
        "                    list_of_train_LDP.append(frames_ldp)\n",
        "                    if train_frame_folder == 'faceforensics_dataset_train/original_sequences':\n",
        "                        list_of_train_labels.append(0)\n",
        "                    else:\n",
        "                        list_of_train_labels.append(1)\n",
        "                frames = []\n",
        "\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Deepfakes.joblib']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ========== ----- ========== SVM Model Training ========== ----- ========== #\n",
        "\n",
        "# param_grid = {'C': [0.1, 1, 5], 'gamma': [1, 0.1, 0.01],\n",
        "#               'kernel': ['linear', 'rbf']}\n",
        "\n",
        "model = svm.SVC(kernel='rbf')\n",
        "# grid = GridSearchCV(model, param_grid, refit=True, n_jobs=-1, verbose=1)\n",
        "model.fit(list_of_train_LDP, list_of_train_labels)\n",
        "\n",
        "# Save the trained model to a file\n",
        "dump(model, 'Deepfakes.joblib')\n",
        "\n",
        "# Load the saved model from the file\n",
        "# loaded_model = load('svm_model.joblib')\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== SVM Model Training ========== ----- ========== #\n",
        "\n",
        "# param_grid = {'C': [0.1, 1, 5], 'gamma': [1, 0.1, 0.01],\n",
        "#               'kernel': ['linear', 'rbf']}\n",
        "\n",
        "model = svm.SVC(kernel='linear')\n",
        "# grid = GridSearchCV(model, param_grid, refit=True, n_jobs=-1, verbose=1)\n",
        "model.fit(list_of_train_LDP, list_of_train_labels)\n",
        "\n",
        "# Save the trained model to a file\n",
        "dump(model, 'Linear-Deepfakes.joblib')\n",
        "\n",
        "# Load the saved model from the file\n",
        "# loaded_model = load('svm_model.joblib')\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DS_LDPcode.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
